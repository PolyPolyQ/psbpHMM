---
title: "Package Tutorial for psbpHMM"
output: rmarkdown::html_vignette
date: June 22, 2021
author: Lauren Hoskovec
vignette: >
  %\VignetteIndexEntry{Package Tutorial for psbpHMM}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction #

The R package psbpHMM provides several functions for fitting covariate-dependent infinite hidden Markov models via the probit stick-breaking process (PSBP). We provide some examples for how to use the package here. First please install the following packages. 

```{r, results = FALSE}
library(Rcpp) 
library(RcppArmadillo)  
library(mvtnorm) 
library(truncnorm)
library(tmvtnorm)
library(parallel)
library(tmvmixnorm)
library(matrixcalc)
library(mvnfast)
library(gdata)
library(invgamma)
library(salso)
library(psbpHMM)
library(gtools)
```

First, let's simulate some data. We provide the function `simdat` for simulating data. We will simulate `n = 10` time series of length `T = 100` from a `p = 3` dimensional multivariate normal hidden Markov model with `K = 5` hidden states shared among all time series. Each time series will have common temporal trends through the hiddens states. We will consider time series with data that is missing at random (MAR) and below a fixed and known limit of detection (LOD). Run the following line to simulate this data: 

```{r, cache=TRUE}
set.seed(42412)
dat = simdat(n=10, t.max = 100, K = 5, p = 3, tempTrend = TRUE, 
             lodRemove = TRUE, marRemove = TRUE, lodmis = 0.025, marmis = 0.025, sf = 0.1)
```

The parameter `sf` controls the level of variation in the state-specific covariance matrices. To simulate data with more noise, increases `sf`. To simulate data with a stronger signal, decrease `sf`. `sf` must be some number greater than 0. 

In these data, 2.5$\%$ of the data is MAR and 2.5$\%$ of the data is below the LOD. Hence, the fixed and known LOD is set at the 0.025 quantile of the pooled data set. 

See the help file to see what the `simdat` function provides.  

```{r}
?simdat
```

We can plot the data to see what it looks like, with the true hidden states color-coded. 

```{r}
plot(1:100, dat$y[[1]][,1], col = dat$z.true[[1]], pch = 19, ylab = "data", xlab = "time")
```

Now, this package provides two functions for fitting a PSBP infinite hidden Markov model (PSBP-iHMM). The first one `miHMM` does not take any covariates. Let's fit this one first. We need to specify the missing data and complete data. See the help file for details. Since there is missing data, we use the MH update for the state-specific covariance matrices, so we must specify the tuning parameters and resolvent kernel parameter. On your own data, be sure to tune these parameters to obtain optimal MH acceptance rates, which are provided in the model output. We will save `len.imp = 20` imputations. Due to the computational complexity of the model, the following line takes approximately 30-40 seconds to run. 

```{r, cache = TRUE}
fit1 = miHMM(niter = 100, nburn = 50, y = dat$y, ycomplete = dat$y.complete, z.true = dat$z.true, lod = dat$lod, 
             mu.true = dat$mu.true, missing = TRUE, tau2 = 0.25, 
             a.tune = 10, b.tune = 1, resK = TRUE, eta.star = 3, len.imp = 20)
```

Next, we simulate some cyclical temporal trends via a harmonic function of time to include as covariates in our covariate-dependent model `mciHMM`. We will assume the time points for each time series all correspond to the same time of day, though they may take place on different days. Any other covariates may be included in this model as well and would be added to the matrix X for each time series. Please note the current version of this model only permits time-varying covariates. In the end, X is a list where each element of the list is a matrix with `T` rows.  

```{r, cache = TRUE}
t.max = 100
n = 10
transT = seq(1:t.max)/t.max*2*pi
X = cbind(sin(transT), cos(transT), sin(2*transT), cos(2*transT))
X1 = list()
for(i in 1:n){
  X1[[i]] = X
}
X = X1
q = ncol(X[[1]])
```

Now we fit the covariate-dependent model `mciHMM`. 

```{r, cache = TRUE}
fit2 = mciHMM(niter = 100, nburn = 50, y = dat$y, rmlist = NULL, ycomplete = dat$y.complete, 
             X = X, z.true = dat$z.true, lod = dat$lod, 
             mu.true = dat$mu.true, missing = TRUE, tau2 = 0.25, 
             a.tune = 10, b.tune = 1, resK = TRUE, eta.star = 3, len.imp = 20)

```

Finally, we can fit a model with subject-specific effects of covariates. To do so, we specify the parameter `rmlist` to provide categorical indicators of the repeated time series for each subject. For example, `rmlist = c(1,1,2,1,3,2,2,3,4,4)` where each integer corresponds to repeated time series for the same subject and different integers correspond to different subjects. The order of the categorical variables in the vector `rmlist` is the order of the time series in the lists `X` and `y` data. We fit the model with the repeated measures specification: 


```{r, cache = TRUE}
rmlist = c(1,1,2,1,3,2,2,3,4,4)
fit3 = mciHMM(niter = 100, nburn = 50, y = dat$y, rmlist = rmlist, ycomplete = dat$y.complete, 
             X = X, z.true = dat$z.true, lod = dat$lod, 
             mu.true = dat$mu.true, missing = TRUE, tau2 = 0.25, 
             a.tune = 10, b.tune = 1, resK = TRUE, eta.star = 3, len.imp = 20)

```

We provide some functions for post-processing the results. The following code applies to all three of our models. We will show on `fit2` only. First, we can calculate the most optimal hidden state trajectory using the draws-based latent structure optimization method described by Dahl (2006). We provide a wrapper function for the `dlso` function in the `salso` R package. 

```{r, cache = TRUE}
zbest = dlso_wrapper(fit2)
```

Given the most optimal hidden state trajectories, we can calculate model-averaged estimates of the state-specific means with `modelAvemu`. 

```{r, cache = TRUE}
ymatrix=NULL
for(i in 1:n){
  ymatrix = rbind(ymatrix, dat$y[[i]])
}
mubest = modelAveMu(fit = fit2, zbest1=zbest, ymatrix = ymatrix)
```

For comparison, we also provide code to fit a truncated Dirichlet process mixture model (DPMM) and a model with fixed and known hidden states. We show how to implement these methods briefly here. See the help files for more details. 

```{r}
fit_dpmm = fitDPMM(niter = 100, nburn = 50, y = dat$y, ycomplete = dat$y.complete, 
             K.start = 50, z.true = dat$z.true, lod = dat$lod, 
             mu.true = dat$mu.true, missing = TRUE, tau2 = 0.25, 
             a.tune = 10, b.tune = 1, resK = TRUE, eta.star = 3, len.imp = 20)
```



```{r}
z_one = lapply(1:n, FUN = function(x){
  return(rep(1,t.max))
})

fit_fixedK = fixedK_clustering(niter = 100, nburn = 50, y = dat$y, ycomplete = dat$y.complete, 
             K.true = 1, z.true = z_one, lod = dat$lod, 
             missing = TRUE, gibbs_update = TRUE)
```

